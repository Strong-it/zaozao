### 介绍Scrapy常用的字段和方法
* name  
定义spider名字的字符串(string)。spider的名字定义了Scrapy如何定位(并初始化)spider，所以其必须是唯一的。 不过您可以生成多个相同的spider实例(instance)，这没有任何限制。 name是spider最重要的属性，而且是必须的。  

  如果该spider爬取单个网站(single domain)，一个常见的做法是以该网站(domain)(加或不加 后缀 )来命名spider。 例如，如果spider爬取 `mywebsite.com` ，该spider通常会被命名为`mywebsite`

* allowed_domains  
可选。包含了spider允许爬取的域名(domain)列表(list)。 当 OffsiteMiddleware 启用时， 域名不在列表中的URL不会被跟进。

* start_urls  
URL列表。当没有制定特定的URL时，spider将从该列表中开始进行爬取。 因此，第一个被获取到的页面的URL将是该列表之一。 后续的URL将会从获取到的数据中提取。
* start_requests()  
该方法必须返回一个可迭代对象(iterable)。该对象包含了spider用于爬取的第一个Request。

    当spider启动爬取并且未制定URL时，该方法被调用。 当指定了URL时，`make_requests_from_url()` 将被调用来创建Request对象。 该方法仅仅会被Scrapy调用一次，因此您可以将其实现为生成器。

    该方法的默认实现是使用`start_urls`的url生成Request。

    如果您想要修改最初爬取某个网站的Request对象，您可以重写(override)该方法。 例如，如果您需要在启动时以POST登录某个网站，你可以这么写
    ```java
    class MySpider(scrapy.Spider):
        name = 'myspider'

        def start_requests(self):
            return [scrapy.FormRequest("http://www.example.com/login",
                                   formdata={'user': 'john', 'pass': 'secret'},
                                   callback=self.logged_in)]

        def logged_in(self, response):
            # here you would extract links to follow and return Requests for
            # each of them, with another callback
            pass
    ```
